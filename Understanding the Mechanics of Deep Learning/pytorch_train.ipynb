{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d7bdee1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5565eedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74b51d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting apex\n",
      "  Using cached apex-0.9.10dev.tar.gz (36 kB)\n",
      "Collecting cryptacular\n",
      "  Using cached cryptacular-1.6.2.tar.gz (75 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Collecting zope.sqlalchemy\n",
      "  Using cached zope.sqlalchemy-1.6-py2.py3-none-any.whl (22 kB)\n",
      "Collecting velruse>=1.0.3\n",
      "  Downloading velruse-1.1.1.tar.gz (709 kB)\n",
      "Collecting pyramid>1.1.2\n",
      "  Downloading pyramid-2.0-py3-none-any.whl (246 kB)\n",
      "Collecting pyramid_mailer\n",
      "  Downloading pyramid_mailer-0.15.1-py2.py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\lenovo\\anaconda3\\envs\\pytorchgpu\\lib\\site-packages (from apex) (2.27.1)\n",
      "Collecting wtforms\n",
      "  Downloading WTForms-3.0.1-py3-none-any.whl (136 kB)\n",
      "Collecting wtforms-recaptcha\n",
      "  Downloading wtforms_recaptcha-0.3.2-py2.py3-none-any.whl (7.5 kB)\n",
      "Collecting zope.deprecation>=3.5.0\n",
      "  Downloading zope.deprecation-4.4.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting translationstring>=0.4\n",
      "  Downloading translationstring-1.4-py2.py3-none-any.whl (15 kB)\n",
      "Collecting plaster-pastedeploy\n",
      "  Downloading plaster_pastedeploy-0.7-py2.py3-none-any.whl (7.8 kB)\n",
      "Collecting venusian>=1.0\n",
      "  Downloading venusian-3.0.0-py3-none-any.whl (13 kB)\n",
      "Collecting hupper>=1.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Building wheel for cryptacular failed: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Lenovo\\\\AppData\\\\Local\\\\Temp\\\\pip-wheel-rmp1ht7m\\\\cryptacular-1.6.2-cp310-cp310-win_amd64.whl'\n",
      "ERROR: Could not build wheels for cryptacular which use PEP 517 and cannot be installed directly\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading hupper-1.10.3-py2.py3-none-any.whl (26 kB)\n",
      "Collecting zope.interface>=3.8.0\n",
      "  Downloading zope.interface-5.4.0.tar.gz (249 kB)\n",
      "Collecting webob>=1.8.3\n",
      "  Downloading WebOb-1.8.7-py2.py3-none-any.whl (114 kB)\n",
      "Collecting plaster\n",
      "  Downloading plaster-1.0-py2.py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lenovo\\anaconda3\\envs\\pytorchgpu\\lib\\site-packages (from pyramid>1.1.2->apex) (61.2.0)\n",
      "Collecting requests-oauthlib\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting anykeystore\n",
      "  Downloading anykeystore-0.2.tar.gz (10 kB)\n",
      "Collecting python3-openid\n",
      "  Downloading python3_openid-3.2.0-py3-none-any.whl (133 kB)\n",
      "Collecting pbkdf2\n",
      "  Downloading pbkdf2-1.3.tar.gz (6.4 kB)\n",
      "Collecting PasteDeploy>=2.0\n",
      "  Downloading PasteDeploy-2.1.1-py2.py3-none-any.whl (17 kB)\n",
      "Collecting repoze.sendmail>=4.1\n",
      "  Downloading repoze.sendmail-4.4.1-py2.py3-none-any.whl (41 kB)\n",
      "Collecting transaction\n",
      "  Downloading transaction-3.0.1-py2.py3-none-any.whl (47 kB)\n",
      "Collecting defusedxml\n",
      "  Downloading defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\envs\\pytorchgpu\\lib\\site-packages (from requests->apex) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\envs\\pytorchgpu\\lib\\site-packages (from requests->apex) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\envs\\pytorchgpu\\lib\\site-packages (from requests->apex) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\lenovo\\anaconda3\\envs\\pytorchgpu\\lib\\site-packages (from requests->apex) (2.0.4)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Collecting MarkupSafe\n",
      "  Downloading MarkupSafe-2.1.1-cp310-cp310-win_amd64.whl (17 kB)\n",
      "Collecting SQLAlchemy!=1.4.0,!=1.4.1,!=1.4.2,!=1.4.3,!=1.4.4,!=1.4.5,!=1.4.6,>=0.9\n",
      "  Downloading SQLAlchemy-1.4.39-cp310-cp310-win_amd64.whl (1.6 MB)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading greenlet-1.1.2-cp310-cp310-win_amd64.whl (101 kB)\n",
      "Building wheels for collected packages: apex, velruse, zope.interface, anykeystore, cryptacular, pbkdf2\n",
      "  Building wheel for apex (setup.py): started\n",
      "  Building wheel for apex (setup.py): finished with status 'done'\n",
      "  Created wheel for apex: filename=apex-0.9.10.dev0-py3-none-any.whl size=46462 sha256=91a43fe2a4fd8f33b277785825a94ce2af093a7c2b07ef57504cee05a27dd3ff\n",
      "  Stored in directory: c:\\users\\lenovo\\appdata\\local\\pip\\cache\\wheels\\6e\\62\\59\\9b100fce7ebd989603b3b7a4ca259150da72c9e107fcaa2a30\n",
      "  Building wheel for velruse (setup.py): started\n",
      "  Building wheel for velruse (setup.py): finished with status 'done'\n",
      "  Created wheel for velruse: filename=velruse-1.1.1-py3-none-any.whl size=50930 sha256=d319c108c885e2e70ccebe9530d1665bbcad09d28414e2763880d42f804d9e61\n",
      "  Stored in directory: c:\\users\\lenovo\\appdata\\local\\pip\\cache\\wheels\\4a\\f9\\a4\\fc4ea7b935ee9c58b9bc772cabd94f6a8560f35444097d948d\n",
      "  Building wheel for zope.interface (setup.py): started\n",
      "  Building wheel for zope.interface (setup.py): finished with status 'done'\n",
      "  Created wheel for zope.interface: filename=zope.interface-5.4.0-cp310-cp310-win_amd64.whl size=210465 sha256=20f8c9ed5acc04e0a7b8e4bf37b082c9a5347e6462e6858f39d3e3eab2f761b8\n",
      "  Stored in directory: c:\\users\\lenovo\\appdata\\local\\pip\\cache\\wheels\\21\\a9\\8b\\0bfc5594d8e109d5b25d6b69e0cff14d09d93e3522dcb16d2b\n",
      "  Building wheel for anykeystore (setup.py): started\n",
      "  Building wheel for anykeystore (setup.py): finished with status 'done'\n",
      "  Created wheel for anykeystore: filename=anykeystore-0.2-py3-none-any.whl size=16833 sha256=b0901010f7dd5140a8c6e52b8c7355ece1665ccc7623ce426d2b1d2a9e9fa2ab\n",
      "  Stored in directory: c:\\users\\lenovo\\appdata\\local\\pip\\cache\\wheels\\ce\\9e\\24\\35542b7d376b53a6f8426524cc5a3f7998f975037b32d19906\n",
      "  Building wheel for cryptacular (PEP 517): started\n",
      "  Building wheel for cryptacular (PEP 517): finished with status 'done'\n",
      "  Building wheel for pbkdf2 (setup.py): started\n",
      "  Building wheel for pbkdf2 (setup.py): finished with status 'done'\n",
      "  Created wheel for pbkdf2: filename=pbkdf2-1.3-py3-none-any.whl size=5105 sha256=87f5443ca1c8a0e6fe25b6e6bb8119a469a2e6be3dfd6dea02485602a6d830f5\n",
      "  Stored in directory: c:\\users\\lenovo\\appdata\\local\\pip\\cache\\wheels\\f6\\7d\\8b\\4269ff90fda80497ec59f6ff7d1e1596cb697c1dc8e9bbe320\n",
      "Successfully built apex velruse zope.interface anykeystore pbkdf2\n",
      "Failed to build cryptacular\n"
     ]
    }
   ],
   "source": [
    "!pip install apex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82f8d807",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'apex'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_36924/2435519220.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#Mixed precision with Apex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mapex\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mamp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mapex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFusedAdam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'apex'"
     ]
    }
   ],
   "source": [
    "################################\n",
    "#Mixed precision with Apex\n",
    "from apex import amp\n",
    "from apex.optimizers import FusedAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d6c6cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul 13 00:59:48 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 516.01       Driver Version: 516.01       CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   40C    P3    14W /  N/A |      0MiB /  4096MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     36924      C   ...novo\\anaconda3\\python.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f86c4a",
   "metadata": {},
   "source": [
    "# TO Make it Run on particular GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d33d541",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICE\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8f78fbb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MODEL_PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_36924/227902459.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m                          nn.Linear(512,4))\n\u001b[0;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MODEL_PATH' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb0b4b43",
   "metadata": {},
   "source": [
    "# use device for cuda or cpu based on availabilty\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0cbcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.device('cuda')  #Default Cuda Device\n",
    "cuda0 = torch.device('cuda:0') #GPU 0\n",
    "cuda2 = torch.device('cuda:2') #GPU 2(These are 0-indexed)\n",
    "\n",
    "x = torch.tensor([1., 2.], device = cuda0)\n",
    "#x.device is deveice(type= cuda, index = 0)\n",
    "y = torch.tensor([1., 2.]).cuda()\n",
    "#x.device is deveice(type= cuda, index = 0)\n",
    "\n",
    "with torch.cudadevice(1):\n",
    "    a = torch.tensor([1., 2.], device = cuda)\n",
    "    #allocates a tensor on GPU 1\n",
    "    \n",
    "    #transfers a tensor from cpu to GPU 1\n",
    "    b = torch.tensor([1., 2.]).cuda()\n",
    "    #a.device and b.device are device(type='cuda', index = 1)\n",
    "    \n",
    "    \n",
    "    #you can also use \"Tensor.to\" to transfer a tensor:\n",
    "    b2 = torch.tensor([1.,2.])to(device=cuda)\n",
    "    #b2.device are device(type='cuda', index = 1)\n",
    "    \n",
    "    c = a+b\n",
    "    #c.device are device(type='cuda', index = 1)\n",
    "    \n",
    "    #even within a context , you can specify the device\n",
    "    d= torch.randn(2, device=cuda2)\n",
    "    e =torch.randn(2).to(cuda2)\n",
    "    f = torch.randn(2).cuda(cuda2)\n",
    "    #d.device , e.device, f.device are all device (type = 'cuda', index)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6241f920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5ce932",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(\"./saved\")\n",
    "except FilesExistsError:\n",
    "    #directory already exists error\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48421e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dicts{\n",
    "    TRAIN_CSV = \"../data/train.csv\",\n",
    "    TEST_CSV = \"../data/test.csv\",\n",
    "    IMAGE_PATH = \"../data/images\",\n",
    "    VOCAB = \"labels.json\"\n",
    "    pretrained_path = \"./pretrained/resnet50-0676ba61.pth \",\n",
    "    saved_paths = \"./saved/resnet50.pt\",\n",
    "    lr=0.001,\n",
    "    EPOCHS = 10,\n",
    "    BATCH_SIZE= 32,\n",
    "    IMAGE_SIZE =224,\n",
    "    TRAIN_VALID_SPLIT =0.2,\n",
    "    ##################################################\n",
    "    #For Performance Tuning\n",
    "    device=device,\n",
    "    SEED= 42\n",
    "    pin_memory=True,\n",
    "    num_workers=8,\n",
    "    USE_AMP = False\n",
    "    channel_last=False \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3231c41",
   "metadata": {},
   "source": [
    "# reproducibilty : Mandate for constant result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92a01f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for custom operators , you might need to set python seed\n",
    "random.seed(config.SEED)\n",
    "#if you are using any of libraries you are usingthar rely on NUMPY, you can seed global the Numpy \n",
    "np.random.seed(config.SEED)\n",
    "#Prevent Random Noise Generator for CPU and GPU using torch\n",
    "torch.manual_seed(config.SEED)\n",
    "torch.cuda_manual(config.SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f51fbb",
   "metadata": {},
   "source": [
    "# # Create tesnor direct on device\n",
    "instead of calling torch.rand(size).cuda() we can directly create tensor on target device : torch.rand(size, device =device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31e52ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.33 s ± 51.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "torch.randn((64,3 ,1280,720)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a63e19d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 23.13 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "48.6 µs ± 86 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "torch.randn((64,3 ,1280,720), device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304f4eec",
   "metadata": {},
   "source": [
    "Cuda Convolution Benchmarking Best Convolution Algo may loose reproducibilty test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f24472cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if reseacher wants to reproduce: False\n",
    "#if developer wants performance :True\n",
    "torch.backends.cudnn.beenchmarks = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0e2b7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for predocubilty in choosing a dterminstic alternative algorithm\n",
    "#this will produce one of the best algorithms\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a034a4c",
   "metadata": {},
   "source": [
    "Enabling TF32 on Ampere GPUs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d73c63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this flag below controls whether to allow TF32 on matmul.This Flag defaults to TRue\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "#this flag below controls whether to allow TF32 on cuDNN.This Flag defaults to TRue\n",
    "torch.backends.cudnn.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00184346",
   "metadata": {},
   "source": [
    "# DAta Manipulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96496992",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(config.TRAIN_CSV)\n",
    "test_df = pd.read_csv(config.TEST_CSV)\n",
    "f = open(config.VOCAB)\n",
    "vocab = json.load(f)\n",
    "\n",
    "df_names = train_df[\"image_id\"].append(test_df[\"images_id\"], ignore_index= True).tolist()\n",
    "def create_fname(path,extension):\n",
    "    def add_extension(fname):\n",
    "        return os.path.join(path,fname)+extension\n",
    "    return add_extension\n",
    "jpeg_extension_creator = create_fname(config.IMAGE_PATH, \"PATH\")\n",
    "train_df[\"image_id\"] = train_df[\"image_id\"].apply(jpeg_extension_creator)\n",
    "test_df[\"image_id\"] = test_df[\"image_id\"].apply(jpeg_extension_creator)\n",
    "for label in vocab:\n",
    "    train_df.loc[train_df[label]==1, \"label\"]= vocab[label]\n",
    "train_df[\"label\"] = train_df[\"label\"].astype(int)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66afc078",
   "metadata": {},
   "source": [
    "Data split (Train and val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c828c92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_X, valid_df_X, train_df_y, valid_df_y = train_test_split(train_df[\"image_id\"],\n",
    "                                                                 train_df[\"label\"],\n",
    "                                                                 test_size = config.TRAIN_VALID_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14412beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_split= pd.DataFrame(data = {\"image_id\": train_df_X, \"label\": train_df_y})\n",
    "train_df_split.to_csv(\"../data/train_split.csv\", sep= ',', index = False)\n",
    "\n",
    "valid_df_split= pd.DataFrame(data = {\"image_id\": valid_df_X, \"label\": valid_df_y})\n",
    "valid_df_split.to_csv(\"../data/train_split.csv\", sep= ',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc84781",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4203af7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(Image.open(train_df_X[0])).dtype"
   ]
  },
  {
   "cell_type": "raw",
   "id": "033be622",
   "metadata": {},
   "source": [
    "--> Image_file_Path (string)\n",
    "--> Image.open(file_path)\n",
    "--> np.array(Image.open(file_path)\n",
    "--> Images [0-255] uint8\n",
    "--> [0-1] z; float32\n",
    "--> X = Mean_training_dataset / std_training_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779fc994",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop((config.IMAGE_SIZE, config.IMAGE_SIZE)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor()\n",
    "        transforms.Normalize([0.485,0.456,0.406], [0.229,0.224.0.225])\n",
    "    ]),\n",
    "    'val':transforms.Compose([\n",
    "        transforms.RandomResizedCrop((config.IMAGE_SIZE, config.IMAGE_SIZE)),\n",
    "        transforms.ToTensor()\n",
    "        transforms.Normalize([0.485,0.456,0.486], [0.229,0.224.0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77c6b56",
   "metadata": {},
   "source": [
    "Custom Dataset and DataLoader for Plant Pathology Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e86f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlantPathologyDataset(Dataset):\n",
    "    def __init__(self, x,y, coab, transforms):\n",
    "        self.x = x #file path in CSV\n",
    "        self.y = y#labe in csv\n",
    "        self.vocab = vocab #Dictionary\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self,idx): #File None --> Preproced 3D Tensors\n",
    "        fname = self.x.iloc[idx]\n",
    "        label = self.yloc[idx]\n",
    "        image = Image.open(fname)\n",
    "        \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "            \n",
    "        return image, label #[3,224,224], [0-3]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b69eaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = PlantPathologyDataset(train_df_X,\n",
    "                                train_df_y,\n",
    "                                vocab,\n",
    "                                data_transforms['train'])\n",
    "valid_ds = PlantPathologyDataset(valid_df_X,\n",
    "                                valid_df_y,\n",
    "                                vocab,\n",
    "                                data_transforms['val']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f354d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b9f534",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds[0][0].shape #3,224,224\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59599998",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of iterations\n",
    "1256/32 #train_len/batchsize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f74824a",
   "metadata": {},
   "source": [
    "GPU Optimzer data loader,\n",
    "\n",
    "Using \n",
    "Pin_Memory = False\n",
    "\n",
    "num_workers =8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9ca897",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds,\n",
    "                     batch_size = config.BATCH_SIZE,\n",
    "                     shuffle = True,\n",
    "                     num_workers = config.num_workers,\n",
    "                     pin_memory= True)\n",
    "valid_dl = DataLoader(valid_ds,\n",
    "                     batch_size = config.BATCH_SIZE,\n",
    "                     shuffle = False,\n",
    "                     num_workers = config.num_workers,\n",
    "                     pin_memory= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19889d02",
   "metadata": {},
   "source": [
    "Loading Pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c640cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#can use model = model.resnet50(pretrained = True)\n",
    "\n",
    "#for download model from \"https://download.putorch.org/models/restnet50-0676ba61.pth\"\n",
    "\n",
    "model = models.resnet50(pretrained=False)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Sequential(nn.Linear(num_ftrs,512),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Dropout(p=0.3),\n",
    "                         nn.Linear(512,4))\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d669261c",
   "metadata": {},
   "source": [
    "# Enable channel_last \n",
    "for computer visions models\n",
    "\n",
    "It is seen as new update in pytorch beta version instead of using CHW format if we use HWC , there is increased peformace that has been measure .\n",
    "\n",
    "you dont change that in your dataLoader part rather change memory_format par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d171b81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.channels_last:\n",
    "    model =model.to(config.device, memory_format = torch.channels_last)#CHW-> HCW\n",
    "else:\n",
    "    model = model.to(config.device)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d990312",
   "metadata": {},
   "source": [
    "# Apex for Fused Optimizer and Automatic Mixed Precision(AMP)\n",
    "\n",
    "FusedAdam does the following\n",
    "\n",
    "Fusion of the Adam update's elementwise opeartions\n",
    "\n",
    "A multi-tensor apply launch that batches elementwise upadtes applied to all the model's parameter into one or few cuda kernel Launches\n",
    "\n",
    "and\n",
    "\n",
    "Mixed precisons leverages Tensor Cores and offers upto 3x overall speedup on volta and newer GPU architecures\n",
    "\n",
    "amp.intialize() wraps the model and optimizer for mixed precesion training.note that model should be already be intialized before calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3590ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.USE_AMP:\n",
    "    optimizer = FusedAdam(model.parameters(), config.lr)\n",
    "    model,optimizer= amp.intialize(model,optimizer, opt_level=\"O2\")#O1/O2/O3\n",
    "else :\n",
    "    optimizer = optim.Adam(model.parameters(), config.lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b593b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss Function\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3379404",
   "metadata": {},
   "source": [
    "# Training Pipeline Starts\n",
    "\n",
    "There another additional thing , is using non_blocking = True ,when we use Pin_Memory = True. This will stop unwated cpying from cpu to GPU ,this is Optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6cf204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,criterion, optimizer, num_epochs=10):\n",
    "    \n",
    "    train.cuda.synchronize()\n",
    "    since = time.time()\n",
    "    batch_ct = 0\n",
    "    example_ct = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch{}/{}'.format(epoch, num_epochs-1))\n",
    "        print('-'*10)\n",
    "        \n",
    "        #training\n",
    "        model.train()\n",
    "        for x,y in train_dl: #BS=32 [BS,3,224,224]\n",
    "            if config.channels_last:\n",
    "                x =x.to(config.device, memory_format=torch.channels_last) #CHW--> HCW\n",
    "            else:\n",
    "                x = x.to(config.device)\n",
    "            y = y.to(config.device) #CHW--> #HWC\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            #optimizer.zero_grad()\n",
    "            optimzer.zero_grad(set_to_none= True)\n",
    "            \n",
    "            \n",
    "            train_logits = model(x)\n",
    "            -, train_preds = torch.max(train_logits)\n",
    "            train_loss = criterion(train_logits,y)\n",
    "            \n",
    "            #Apply backward pass on scaled loss function\n",
    "            if config.USE_AMP:\n",
    "                with amp.scale_loss(train_loss, optimizer) as scaled_loss:\n",
    "                    scaled_loss.backward()\n",
    "                    loss = scaled_loss\n",
    "                    \n",
    "            else:\n",
    "                train_loss= loss.backward() #this where we get W_gradients\n",
    "                \n",
    "            \n",
    "        #validation\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        total=0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x,y valid_dl:\n",
    "                if config.channels_last:\n",
    "                    x = x.to(config.device, memory_format= torch.channels_last)\n",
    "                else:\n",
    "                    x= x.to(config.device)\n",
    "                y= y.to(config.device)\n",
    "                valid_logits = model(x)\n",
    "                -, valid_preds = torch.max(valid_logits,y)\n",
    "                running_loss += valid_loss.item() * x.size(0)\n",
    "                running_corrects += torch.sum(valid_preds == y.data)\n",
    "                total += y.size(0)\n",
    "                \n",
    "        epoch_loss = running_loss/len(valid_ds)\n",
    "        epoch_acc = running_corrects.double()/ len(valid_ds)\n",
    "        print(\"valid loss is {}\".format(epoch_loss))\n",
    "        print(\"valid accuracy is {}\".format(epoch_acc.cpu()))\n",
    "        \n",
    "    torch.cuda.synchronize()\n",
    "    time_elasped = time.time() -since\n",
    "    print('Training complete in {:0f}n {:0f}s'.format(\n",
    "    time_elasped //60, time_elasped % 60))\n",
    "        \n",
    "    torch.save(model.state_dict(), config.saved_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6331552",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, criterion, optimizer, num_epochs = config.EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95a09d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b3ac77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6a4e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf144251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66da2019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5636b17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb47f30f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f5b5c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbfff84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cf1fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5ab1e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f891430e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9a72a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d482c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b26eb6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d329090b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd15091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a833212",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c0fa33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133f011f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d86aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a10406d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f945dbb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01f3850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c094eb4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd80b673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8cd200",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e24d45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29552c7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccd5e22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fc3397",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
